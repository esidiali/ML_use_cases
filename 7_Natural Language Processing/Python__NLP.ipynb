{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### to display full column's content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## since we are analyzing text it may contain commas so python read it as column, to avoid that we will read the tsv file \n",
    "## tsv : tab separated values\n",
    "dataset = pd.read_csv('Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3)\n",
    "\n",
    "# quoting is a parameter for quotes, and 3 is the code's value to ignore quotes \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so were the prices.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                    Review  \\\n",
       "0  Wow... Loved this place.                                                                  \n",
       "1  Crust is not good.                                                                        \n",
       "2  Not tasty and the texture was just nasty.                                                 \n",
       "3  Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.   \n",
       "4  The selection on the menu was great and so were the prices.                               \n",
       "\n",
       "   Liked  \n",
       "0  1      \n",
       "1  0      \n",
       "2  0      \n",
       "3  1      \n",
       "4  1      "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### we need to get rid of words that won't help the machine learning algo to predict if the review is good or bad (or, and, ponctuation...), we will also apply stemming, which consist of taking the roots of the differents versions of same word (loved --> love)\n",
    "\n",
    "###### we will also do some tokenization, it will split a review to words, whic, thx to the text-preprocessing, will only be relevent words\n",
    "\n",
    "### first clean the first review, then apply cleaning techniques using a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re ## regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wow... Loved this place.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st step: only keeping letters in the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wow    Loved this place '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][0] ) ## ' ' te replace the removed character by space\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd step: putting all letters in lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wow    loved this place '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = review.lower()\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd step: Removing non-significant words (which won't help the model to predict nature of review + -)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the idea is to make a loop to go over the words in the review and check if the wors is in the stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow', 'loved', 'this', 'place']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert review to a list\n",
    "review = review.split()\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow', 'loved', 'place']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## review is now a list\n",
    "review = [word for word in review if not word in set(stopwords.words('english')) ] ## set just in case we have largest review\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4th step: Stemming: keep the root of the words   loved = love"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow', 'love', 'place']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = [ps.stem(word) for word in review if not word in set(stopwords.words('english')) ]\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loved becomes love"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5th step: join back the words of the list review, so it becomes one string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wow love place'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = ' '.join(review)\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now apply the same step to all reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_list =[]  ### a corpus is a collection of text\n",
    "for i in range (0, len(dataset)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i] )\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english')) ]\n",
    "    review = ' '.join(review)\n",
    "    corpus_list.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow love place',\n",
       " 'crust good',\n",
       " 'tasti textur nasti',\n",
       " 'stop late may bank holiday rick steve recommend love',\n",
       " 'select menu great price']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Wow... Loved this place.                                                               \n",
       "1    Crust is not good.                                                                     \n",
       "2    Not tasty and the texture was just nasty.                                              \n",
       "3    Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.\n",
       "4    The selection on the menu was great and so were the prices.                            \n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Review'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Bag of Words model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What's We're going to do to create this backwards  model is just to take all the different words of the 1000 reviews.\n",
    "###### So we will take a while. \"Love place crust good tested text nasty\" and all the other words down to the 1000s review without taking twice or three times the duplicates or triplicates we are just taking all the different but unique words of these 1000 reviews and basically then what we'll do is to create one column for each word. So of course there are a lot of different words here so we will have a lot of columns and then we will put all these columns in a table where the rows are nothing else than the 1000 reviews. So basically what we'll get is a table containing 1000 rows where the rows correspond to the reviews and a lot of columns where the columns correspond to each of the different words we can find here in all the reviews in this corpus. So each cell of this table will correspond to one specific review and one specific word of this corpus. And in this cell we're going to have a number and this number is going to be the number of times the word corresponding to the column appears in the review.So for example let's say that you know the first column corresponds to the word: Wow. Well for this particular first column and for the first line that corresponds to the first review that is this one well since Wow appears once in the first review. Well we'll get to one in this particular cell because this cell belongs to the column that corresponds to Wow and well appears once in the review. But then if we stay in this first column and move onto the second row. Well since Wow doesn't appear anywhere in the second review we will get a zero for this particular cell belonging to the first column and the second row. So as you can imagine for most of the cells will have a zero because we can simply see that with this wow word  which will be one of the column and we can see that this word appears only in the first review.\n",
    "\n",
    "#### what it is why do we need to create such a model such a representation.\n",
    "\n",
    "###### Well it's because simply what we'll do in the end is to predict if a review is positive or negative. And for our machine learning model to be able to predict that well it needs to be trained on all these reviews because for all these reviews we have the real results that is we know for each one if it is positive or negative so we will train our algorithm on all these reviews because we have the results and the machine learning model will understand how to make the correlations between the hints that tell if the review is positive or negative and it's true result whether it is positive or negative. So it will make some correlations between the words there and the reviews and the real result. But in order for machine learning model to be trained to predict if a review is positive or negative, it needs to have some independent variables and one dependent variable because simply what we're doing here is classification because the outcome the dependent variable is a categorical variable a binary outcome one is a review positive or zero if the reviews negative. So we are doing nothing else than classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "##### X matrix of features (independent variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus_list).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1565)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X has 1000 lines and 1565 words (columns) (all words used in the 1000 rows). Imagine we have 1 million reviews to analyze and train our mode, well then we will get more than 1 million words (columns) which will lead to huge spasity. So, we add the max_features parameter in CountVectorizer object to keep the most frequent words (relevant ones), lets choose 1500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=1500)\n",
    "X = cv.fit_transform(corpus_list).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1500)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the dependent variable (liked clumn + - review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght of train set :800\n",
      "lenght of train set :200\n"
     ]
    }
   ],
   "source": [
    "print('lenght of train set :' + str(len(X_train))+ '\\nlenght of train set :' + str(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Naive Bayes to the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "## cm= [TP FP]\n",
    "##     [FN TN]\n",
    "TP = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TN = cm[1][1]\n",
    "\n",
    "### metrics\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "Precision = TP / (TP + FP)\n",
    "Recall = TP / (TP + FN)\n",
    "F1_Score = 2 * Precision * Recall / (Precision + Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55 42]\n",
      " [12 91]]\n",
      "model's ACCURACY is : 0.730%\n",
      "model's PRECISION is : 0.567%\n",
      "model's RECALL is : 0.821%\n",
      "model's F1 SCORE is : 0.671%\n"
     ]
    }
   ],
   "source": [
    "print(cm)\n",
    "print( \n",
    "      \"model's ACCURACY is : \" + str(\"%.3f\" %  Accuracy) +\"%\" +   ## \"%.3f\" % to keep 3 numbers after the comma\n",
    "      \"\\nmodel's PRECISION is : \" + str(\"%.3f\" % Precision) + \"%\"+ ## we could also use format(x, '.2f')\n",
    "      \"\\nmodel's RECALL is : \" + str(\"%.3f\" % Recall) + \"%\"+\n",
    "      \"\\nmodel's F1 SCORE is : \" + str(\"%.3f\" % F1_Score) + \"%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### over 200 review, the model predicted 55 correct negative reviews and 9 correct positive reviews\n",
    "###### if we had a 1 million reviews it would be more accurate, but for 800 review it's not bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest to the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[87, 10],\n",
       "       [46, 57]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=10, criterion= \"entropy\", random_state=0)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm\n",
    "## cm= [TP FP]\n",
    "##     [FN TN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TN = cm[1][1]\n",
    "\n",
    "### metrics\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "Precision = TP / (TP + FP)\n",
    "Recall = TP / (TP + FN)\n",
    "F1_Score = 2 * Precision * Recall / (Precision + Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87 10]\n",
      " [46 57]]\n",
      "model's ACCURACY is : 0.720%\n",
      "model's PRECISION is : 0.897%\n",
      "model's RECALL is : 0.654%\n",
      "model's F1 SCORE is : 0.757%\n"
     ]
    }
   ],
   "source": [
    "print(cm)\n",
    "print( \n",
    "      \"model's ACCURACY is : \" + str(\"%.3f\" %  Accuracy) +\"%\" +   ## \"%.3f\" % to keep 3 numbers after the comma\n",
    "      \"\\nmodel's PRECISION is : \" + str(\"%.3f\" % Precision) + \"%\"+ ## we could also use format(x, '.2f')\n",
    "      \"\\nmodel's RECALL is : \" + str(\"%.3f\" % Recall) + \"%\"+\n",
    "      \"\\nmodel's F1 SCORE is : \" + str(\"%.3f\" % F1_Score) + \"%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "less accurate than Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM to the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74 23]\n",
      " [33 70]]\n",
      "model's ACCURACY is : 0.720%\n",
      "model's PRECISION is : 0.763%\n",
      "model's RECALL is : 0.692%\n",
      "model's F1 SCORE is : 0.725%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier =SVC(kernel='linear', random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "## predict\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "TP = cm[0][0]  ## true positive\n",
    "FP = cm[0][1]  ## false positive\n",
    "FN = cm[1][0]  ## false negative\n",
    "TN = cm[1][1]  ## true negative\n",
    "\n",
    "### metrics\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "Precision = TP / (TP + FP)\n",
    "Recall = TP / (TP + FN)\n",
    "F1_Score = 2 * Precision * Recall / (Precision + Recall)\n",
    "\n",
    "## print\n",
    "print(cm)\n",
    "print( \n",
    "      \"model's ACCURACY is : \" + str(\"%.3f\" %  Accuracy) +\"%\" +   ## \"%.3f\" % to keep 3 numbers after the comma\n",
    "      \"\\nmodel's PRECISION is : \" + str(\"%.3f\" % Precision) + \"%\"+ ## we could also use format(x, '.2f')\n",
    "      \"\\nmodel's RECALL is : \" + str(\"%.3f\" % Recall) + \"%\"+\n",
    "      \"\\nmodel's F1 SCORE is : \" + str(\"%.3f\" % F1_Score) + \"%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we use a gaussian kernel here the result won't be good"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
